### Optimization

- Stochastic Gradient Descent and it's many variants
- Optimizers
	- SGD
	- Adam
	- RMSProp
	- etc...
	- Talk about momentum (maybe too specific)

> linked from:
- Linear Regression