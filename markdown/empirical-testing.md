# Empirical Testing

- So much in ML relies on emperical testing
	- Which activation function
	- What hyperparameters
	- How wide/deep?
	- What network architecture to use?
	- What type of regularization

- The truth is that there is so much that we don't yet understand about ML. We are at just the tip of the iceberg when it comes to ML discovery and understanding. We can mathematically prove that neural networks with unlimited neurons can model [any function](general-purpose-algorithms.html), but we don't yet know how to train them effectively. Huge progress has been made in this area recently, but ultimately ML researchers are poking around in the dark to find answers like. Often solutions or techniques work but there is very little explanation or understanding as to why. It is for this reason that training ML models is sometimes considered more of an art than a science.  