## Neural Networks and Deep Learning

- Multi-layer perceptron (1960s style)
- Super brief overview of a single-layer feed forward MLP
	- Input, multiply weights, add biases, activation function, output (repeat per layer)
	- should this also include the anatomy of a neural network?
		- activation functions
- Layers represent heirarchy of information
- Activation functions bend otherwise liner models
