# Normalization and Whitening

Most machine learning algorithms only perform well on data that has been properly prepaired. In practice it is almost always preferable to scale our input data and shift the mean to zero before passing it to our model. We then both train and deploy our model using scaled input. So long as you apply the same normalization techniques to your test and production data that you did to the training data, the performance of your algorithm should greatly improve.

## Zero-Mean and Unit Variance



## Feature-Wise Normalization

- Feature-wise normalization
- Zero mean and unit variance
- Or everything between 0 and 1 (or -1 and 1)
