<!DOCTYPE html>
<html lang="en">
    <head>
        <!--
              +++++++++++++
            +++++++++++++++++
          +++++++++++++++++++++
         +++++++ ---------- ++++       ____                                         ____       _
        ++++++++|  ______  |+++++     |  _ \                                       |  _ \     (_)
        ++++++__| |______| |+++++     | |_) |_ __ __ _ _ __   __ _  ___ _ __       | |_) |_ __ _ ____
        +++++|  _________  |+++++     |  _ <| '__/ _` | '_ \ / _` |/ _ \ '__|      |  _ <| '__| |_  /
        +++++| |_________| |+++++     | |_) | | | (_| | | | | (_| |  __/ |         | |_) | |  | |/ /
         ++++|_____________|++++      |____/|_|  \__,_|_| |_|\__, |\___|_| _______ |____/|_|  |_/___|
          +++++++++++++++++++++                              __ | |       |_______|
            +++++++++++++++++                                \___/
              +++++++++++++
        -->
        <meta charset="utf-8">
        <meta http-equiv="x-ua-compatible" content="ie=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1">

        <title> Branger_Briz </title>

        <link rel="icon" type="image/png" href="images/bb.svg">
        <meta name="description" content="we are a full足service digital agency+lab made up of artists, strategists, educators && programmers bent on articulating contemporary culture. we produce award winning work for brands, agencies, and cultural institutions around the world.">

        <!-- for Google+ -->
        <meta itemprop="name" content="Branger_Briz">
        <meta itemprop="description" content="we are a full足service digital agency+lab made up of artists, strategists, educators && programmers bent on articulating contemporary culture">
        <meta itemprop="image" content="images/bb.svg">
        <!-- for Twitter -->
        <meta name="twitter:card" content="summary_large_image">
        <meta name="twitter:site" content="@branger_briz">
        <meta name="twitter:title" content="Branger_Briz">
        <meta name="twitter:description" content="we are a full足service digital agency+lab made up of artists, strategists, educators && programmers bent on articulating contemporary culture.">
        <meta name="twitter:creator" content="@branger_briz">
        <!-- Twitter summary card with large image must be at least 280x150px -->
        <meta name="twitter:image:src" content="images/bb.svg">
        <!-- for Facebook -->
        <meta property="og:title" content="Branger_Briz">
        <meta property="og:type" content="article">
        <meta property="og:url" content="http://brangerbriz.com/">
        <meta property="og:image" content="images/bb.svg">
        <meta property="og:description" content="we are a full足service digital agency+lab made up of artists, strategists, educators && programmers bent on articulating contemporary culture.">
        <meta property="og:site_name" content="Branger_Briz">

        <!-- CSS -->
        <!-- consider including normalize.css -->
        <link rel="stylesheet" href="css/bb-fonts.css">
        <link rel="stylesheet" href="css/bb-styles.css">
        <link rel="stylesheet" href="css/bb-responsive.css"><!-- optional media-queries -->
        <link rel="stylesheet" href="css/bb-code-colors.css"><!-- optional syntax highlighting -->
        <link rel="stylesheet" href="css/bb-animations.css"><!-- optional intro animations -->

    </head>
    <body>
        <section id="logo"></section>
<!-- The content below this line is injected using `marked` in `build.sh` -->
<h1 id="machine-learning-pipeline">Machine Learning Pipeline</h1>
<section class="media" data-fullwidth="false">
    <img src="images/ml-pipeline.png" alt="The machine learning pipeline">
</section>

<h2 id="get-data">Get Data</h2>
<p>The first step in any machine learning pipeline is data acquisition. There are generally four methods of obtaining data:</p>
<ul>
<li>Use a <a href="https://github.com/caesar0301/awesome-public-datasets" target="_blank">publicly available dataset</a></li>
<li>Scrape data from an API or service</li>
<li>Use a private dataset you or your company has collected</li>
<li>Design and deploy a method for collecting or creating new data</li>
</ul>
<p>The first three are fairly similar. The last provides the power to design custom features with the trade-off of money and time. That said, creating your own dataset is definitely something that should be encouraged in the right circumstance. Sometimes it is tempting to limit the scope of the problems that can be solved by the types of data that you have readily available. If you are using ML to solve a problem for which no <em>perfect</em> dataset exists, instead think of ways that you may be able to leverage combinations of existing data, or maybe better yet, create a system by which you can create new data that you can then use to train a model.<span class="marginal-note" data-info="Our [person-to-person translation experiment](https://twitter.com/brannondorsey/status/808461108881268736) using pix2pix necessitated the creation of our own dataset. We ended up creating [a tool](https://github.com/brangerbriz/pix2pix_genData) by which we could take still images that mimicked those of a source video. Once the tool was created, we spent several hours creating a dataset of 1,000 unique images using it."></span></p>
<h2 id="clean-and-pre-process-data">Clean and Pre-process Data</h2>
<p>The data preparation, preprocessing and normalization
<span class="marginal-note" data-info="[Machinelearningmastery.com](https://machinelearningmastery.com/how-to-prepare-data-for-machine-learning/) has a great blog post on how to prepare data for machine learning. In general, I've found this website to be a very helpful resource, especially when it comes to code examples."></span>
 steps are often the most time consuming and code-heavy part of the pipeline (see <a href="normalization-and-preprocessing.html">Preprocessing &amp; Normalization</a>). It&#39;s also the most important step to get right. Most machine learning algorithms only operate well on data that is within a certain range (e.g. small values between <code>-1.0</code> and <code>1.0</code> or <code>0.0</code> and <code>1.0</code>) with a standard variance. Real-world data might have arbitrary values with units in the millions, or tons of outliers that need to be removed. Once you&#39;ve cleaned and pre-processed your data, you will need split it into groups to be used for training and testing. Correctly preparing and partitioning your data before using it for training is often the key to developing a successful model.</p>
<h2 id="train-your-model">Train Your Model</h2>
<p>Now comes the fun part, its time to train your model (using your training data only).
<span class="marginal-note" data-info="[Here](https://elitedatascience.com/model-training) is a nice short tutorial that gives an alternative overview to model training, and the ML pipeline in general."></span>
 Training can take anywhere from a few minutes to hours or days depending on your model architecture or compute hardware. As a rule of thumb, training your model on a GPU will yield training times orders of magnitude faster than CPU training and should almost always be preferenced.</p>
<p>During the training process, your data is iteratively fed into the model in small batches, subsets of the entire training dataset, called mini-batches. Once your model has seen all of the training data, it has completed one epoch. Training usually requires multiple epochs and ends when <a href="https://bit.ly/1CHXsNH" target="_blank">validation loss</a> (error) stops decreasing. More on that soon...</p>
<h2 id="evaluate-your-model">Evaluate Your model</h2>
<p>Once you&#39;ve trained your model, its time to evaluate its performance (see <a href="performance-measures.html">Performance Measures</a>). You usually do this by freezing the model parameters, running the model on the test data, but this time without updating the parameters like you do during training. During evaluation the goal is to measure the trained model&#39;s error/accuracy on unseen data. Once you&#39;ve got a measure of how effective your model is, its time to train another model to try and beat it. The ML pipeline often requires many iterations of training and evaluating; the goal being to reduce the error on your test data.
<span class="marginal-note" data-info="Here are a few things to consider when considering what to change to improve your model's performance: 1) Are you underfitting or overfitting? 2) Adjust values in orders of magnitude (value, value * 10, value * 100, etc) when you are trying to find the right value for something like a hyperparameter, you will cover ground more quickly. 3) Only change one thing at a time between experiments. Changing more introduces ambiguity in what caused the results. Additionally, [This blog post](https://machinelearningmastery.com/improve-deep-learning-performance/) has some good pointers for improving deep learning performance."></span>
It is not uncommon to do this <code>10</code> to <code>100+</code> times, choosing to use the model that performs the best on the testing data in production. For this reason, it is important to keep track of different experiments in an organized way.
<span class="marginal-note" data-info="Keeping track of changes and results from experiments is **super important**! Keep each experiment (trained model) in a separate place, and save all of the information you need to reproduce the experiment alongside it (notes, hyperparameter values, etc.). Here is an [example](https://gist.github.com/brannondorsey/5bd30f894c3dd3a9f290068c92156dba) of a directory structure that I use frequently, as well as a [similar approach](https://andrewhalterman.com/2018/03/05/managing-machine-learning-experiments/) by Andy Halterman."></span>
An advanced technique to quickly and effectively automate the training and evaluation cycle is to use <a href="https://cloud.google.com/ml-engine/docs/tensorflow/hyperparameter-tuning-overview" target="_blank">hyperparameter search</a>.</p>
<h2 id="deploy-your-model">Deploy Your Model</h2>
<p>Once you&#39;ve got a trained model that performs adequately it&#39;s time to deploy it live. This process of using your trained model, called model <em>inference</em> instead of <em>learning</em>
<span class="marginal-note" data-info="Model inference is usually just like model training, but you don't update the weights in the process. Instead the best trained model is &quot;frozen&quot;, test/production data is fed in, and you use the output as the model prediction. How choose to sample from the output prediction can change from model training though. In some cases you sample from the output probability distribution and in others you may choose the output unit with the highest value (e.g. greedy argmax sampling)."></span>
, looks different for every application, but can include things like integrating it into a server-side process that handles web API requests, bundling it in a mobile application, or using <a href="https://js.tensorflow.org" target="_blank">Tensorflow.js</a> to deploy it to the web. Most models are trained to learn model weights that are then frozen during production. However, some models incorporate live unseen data into the training process. These models are said to operate, &quot;online&quot;, and their is little distinction between training and deployment; the model is always learning.</p>
<p>Next: <a href="types-of-learning.html">Types of Learning</a><br>
Previous: <a href="machine-learning-models.html">Machine Learning Models</a></p>

<!-- The content above this line is injected using `marked` in `build.sh` -->    
        <p>Return to the <a href="index.html">main page</a>.</p>
        <p style="font-size: 80%;">
           All source code in this document is licensed under the <a href="https://www.gnu.org/licenses/gpl-3.0.en.html">GPL v3</a> or any later version.
           All non-source code text is licensed under a <a href="https://creativecommons.org/licenses/by-sa/4.0/">CC-BY-SA 4.0</a> international license. 
           You are free to copy, remix, build upon, and distribute this work in any format for any purpose under those terms.
        </p>
        <br>
        <script src="js/BBElements/highlightJS/highlight.pack.js"></script>
       <script src="js/BBElements/BBElements.js"></script>
    </body>
</html>