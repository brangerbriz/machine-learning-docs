<!DOCTYPE html>
<html>
<head><meta charset='utf-8'>
  <title>markdown/the-ml-pipeline.md</title>
  <link rel="stylesheet" href="css/github-markdown.css">
</head>
<body class='markdown-body'>
<h1 id="machine-learning-pipeline">Machine Learning Pipeline</h1>
<p><img src="images/ml-pipeline.png" alt="The Machine Learning Pipeline"></p>
<h2 id="get-data">Get Data</h2>
<p>The first step in any machine learning pipeline is data acquisition. There are generally four methods of obtaining data:</p>
<ul>
<li>Use a <a href="https://github.com/caesar0301/awesome-public-datasets">publicly available dataset</a></li>
<li>Scrape data from a publicly accessible API or service</li>
<li>Use a private dataset you or your company has collected</li>
<li>Design and deploy a method for collecting new data</li>
</ul>
<p>The first three are fairly similar. The last provides the power to design custom features with the trade-off of money and time.</p>
<h2 id="clean-and-pre-process-data">Clean and Pre-process Data</h2>
<p>The data preparation, <a href="data-preprocessing.html">pre-processing</a> and <a href="normalization-and-whitening.html">normalization</a> steps are often the most time consuming and code-heavy part of the pipeline. It&#39;s also the most important step to get right. Most machine learning algorithms only operate well on data that is within a certain range (e.g. small values between <code>-1.0</code> and <code>1.0</code> or <code>0.0</code> and <code>1.0</code>) with a standard variance. Real-world data might have arbitrary values with units in the millions, or tons of outliers that need to be removed. Correctly preparing your data before using it for training is often the key to developing a successful model.</p>
<h2 id="train-your-model">Train Your Model</h2>
<p>Now comes the fun part, its time to <a href="training.md">train your model</a> (using your training data only). Training can take anywhere from a few minutes to hours or days depending on your <a href="model-architecture.html">model architecture</a> or <a href="gpu-hardware.html">compute hardware</a>. As a rule of thumb, training your model on a GPU will yield training times orders of magnitude faster than CPU training and should almost always be referenced. </p>
<p>During the training process, your data is iteratively fed into the model in small batches, subsets of the entire training dataset, called mini-batches. Once your model has seen all of the training data, it has completed one epoch. Training usually requires multiple epochs and ends when <a href="cross-validation.html">validation loss</a> (error) stops decreasing. More on that soon... </p>
<h2 id="evaluate-your-model">Evaluate Your model</h2>
<p>Once you&#39;ve trained your model, its time to <a href="performance-measures.html">evaluate its performance</a>. You usually do this by freezing the model parameters, running the model on the test data without updating the parameters like you do during training. During evaluation the goal is to measure the trained model&#39;s error/accuracy on unseen data. Once you&#39;ve got a measure of how effective your model is, its time to train another model to try and beat it. The ML pipeline often requires many iterations of training and evaluating; the goal being to reduce the error on your test data. It is not uncommon to do this <code>10</code> to <code>100+</code> times, choosing to use the model that performs the best in production. For this reason, it is important to keep track of <a href="experiment-structure.html">different experiments</a> in an organized way. An advanced technique to quickly and effectively automate the training and evaluation cycle is to use <a href="hyperparameter-search.html">hyperparameter search</a>.</p>
<h2 id="deploy-your-model">Deploy Your Model</h2>
<p>Once you&#39;ve got a trained model that performs adequately it&#39;s time to deploy it live. This process looks different for every application, but can include things like integrating it into a server-side process that handles web API requests or bundling it in a mobile application. Most models are trained to learn model weights that are then frozen during production. However, some models incorporate live unseen data into the training process. <a href="online-models.html">These models</a> are said to operate, &quot;online&quot;, and their is little distinction between training and deployment; the model is always learning.</p>
<p>Next: <a href="types-of-learning.html">Types of Learning</a></p>
</body>
</html>
