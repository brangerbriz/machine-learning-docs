<!DOCTYPE html>
<html>
<head><meta charset='utf-8'>
  <title>markdown/types-of-learning.md</title>
  <link rel="stylesheet" href="css/github-markdown.css">
</head>
<body class='markdown-body'>
<h1 id="types-of-learning">Types of learning</h1>
<p>There are two general categories that ML algorithms usually fall into: supervised and unsupervised.</p>
<h2 id="supervised">Supervised</h2>
<p>Supervised learning relies on labeled data to train a model. For each piece of input data <code>X</code> in a training set, there exists a corresponding labeled output data <code>y</code>. For example, a picture of a truck will have the corresponding class label, &quot;truck&quot;. This type of data is very easy to learn from and it is for this reason most traditional machine learning algorithms are supervised. You can think of supervised machine learning as analogous to training an animal. During training, the model is rewarded for correct predictions of <code>y</code> and punished for incorrect predictions of <code>y</code>. If you have labeled data, supervised learning is certainty the way to go. Common downfalls with supervised learning is that labeled data is often scarce. There is far more unlabeled data in the world than labeled data and labeling can often be cost- or time-prohibitive.</p>
<p>One common misconception newcomers often have about supervised learning is that it requires human supervision in some way. While this is often true, as in the case of using a dataset that has been hand-labeled, many supervised learning algorithms leverage data that is &quot;self-labeled&quot;. Take for example a <a href="https://karpathy.github.io/2015/05/21/rnn-effectiveness/">character-level language modeling</a> task that attempts to predict the next letter in a sentence given the previous five letters. To predict the string &quot;hi there!&quot;, an input of &quot;hi th&quot; should output &quot;e&quot;, and &quot;i the&quot;, should output &quot;r&quot;, etc... We could train such a model on the entire 27 billion English characters in Wikipedia without the need for any human supervision. This remains a supervised learning task, because each piece of input data has a corresponding output data that is labeled.</p>
<p>In situations where data is not self-labeling, labeling it can be expensive. It is for this reason that recent research initiatives have put more resources towards developing better unsupervised learning algorithms.</p>
<h2 id="unsupervised">Unsupervised</h2>
<p>Unsupervised learning algorithms learn from unlabeled data. This is particularly advantageous because unlabeled data is cheap and abundant. New developments in unsupervised learning have the potential to make some of the most radical advances for the ML field in the coming decades. Clustering algorithms like <a href="knn.html">K-Nearest Neighbor</a> (k-NN) and <a href="t-sne.html">t-SNE</a> both attempt to group unlabeled data into classes or geometric regions. Both of these methods are incredibly helpful processes used to <a href="learning-about-your-data.html">learn about your data</a>.</p>
<p><a href="network-types.html">Generative Adversarial Networks (GANs)</a> use a novel model dichotomy that pits networks against each-other in order to strengthen both of them. Most of the example algorithms in this document will be supervised in nature, however, we will also make an attempt to cover the basics of unsupervised learning.</p>
<p>Next: <a href="types-of-tasks.html">Types of Tasks</a></p>
</body>
</html>
