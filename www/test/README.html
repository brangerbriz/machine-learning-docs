<!DOCTYPE html>
<html>
<head>
  <title>markdown/test/README.md</title>
  <link rel="stylesheet" href="www/css/github-markdown.css">
</head>
<body class='markdown-body'>
<h1 id="muse-supercuts-for-warner-music-co-">Muse supercuts for Warner Music co.</h1>
<p>This project is a hard fork of Sam Lavigne&#39;s <a href="https://github.com/antiboredom/videogrep">videogrep</a>. See <a href="videogrep_README.md">videogrep_README.md</a> for the original videogrep README. We&#39;ve hijacked/leveraged many of the features from videogrep (like the word-level text-to-speech indexing provided by CMU Sphinx) and added additional code to <code>videogrep/videogrep.py</code> for our purposes. All Warner specific command-line arguments that have been added to videogrep are prefixed with <code>--warner-*</code>. The bulk of aditional code lives in the <code>videogrep/warner.py</code> module. Our additions to <code>videogrep.py</code> include:</p>
<ul>
<li>Index and splice word-level clips and save them to a directory where each clip is inside a folder corresponding to the word it represents (<code>--warner-clip-dir</code>)</li>
<li>Generate Muse song hypercuts with <code>--warner-generate</code></li>
</ul>
<h2 id="getting-started">Getting Started</h2>
<p>Before beginning the video creation pipeline you must install the necessary dependencies. <a href="https://github.com/cmusphinx/sphinxbase"><code>sphinxbase</code></a> and <a href="https://github.com/cmusphinx/pocketsphinx"><code>pocketsphinx</code></a> must both be installed on your machine. <code>ffmpeg</code> must also be installed.</p>
<p>The python dependencies can be installed with <code>pip install -r requirements.txt</code>, or optionally using a virtual environment with:</p>
<pre><code class="lang-bash">virtualenv venv
source venv/bin/activate
pip install -r requirements
</code></pre>
<p>As a word of caution, much of the below process is very compute intensive. It is not uncommon for some processes to require 16-32 GB of RAM to complete (namely <code>run.sh transcribe</code>).</p>
<h2 id="creating-muse-music-videos">Creating Muse Music Videos</h2>
<p>This project necessetates the completion of six basic tasks to generate a video.</p>
<ol>
<li>download source videos to <code>data/input/</code> (and <code>data/input_silence</code>)</li>
<li>transcribe all source videos using CMU sphinx</li>
<li>cut all transcribed videos into word clips saved to <code>data/clips/</code></li>
<li>create a silence supercut to be used as &quot;background&quot; for the music video (using clips from <code>input_silence</code>)</li>
<li>create the music video supercut</li>
<li>overlay closed captions using ffmpeg</li>
</ol>
<p>Each step can be completed using <code>run.sh [ARG [ARG [...]]]</code>. Supported arguments include:</p>
<ol>
<li><code>download</code></li>
<li><code>clean</code></li>
<li><code>transcribe</code></li>
<li><code>cut</code></li>
<li><code>cut-silence</code></li>
<li><code>silence</code></li>
<li><code>supercut</code></li>
<li><code>subs</code></li>
</ol>
<p>E.g. to run all tasks <code>./run.sh download clean transcribe cut cut-silence silence supercut subs</code>. If no arguments are provided to <code>run.sh</code> all 8 tasks are executed. Tasks can be run individually like <code>./run.sh transcribe</code>.</p>
<h3 id="1-download-source-videos">1. Download source videos</h3>
<p><code>./run.sh download</code> downloads YouTube videos from video or playlist URLs found in <code>data/input/download.txt</code> and saves them to <code>data/input/</code>.<br>Once downloaded, the script moves the URLs in <code>data/input/download.txt</code> to <code>data/input/sources.txt</code>.</p>
<p><strong>When downloading silence videos, manually change the <code>--output</code> directory in <code>run.sh: download()</code> to output to <code>data/input_silence</code> instead of <code>data/input</code></strong>.</p>
<p>It is recommended that you use <code>./run.sh download</code> instead of manually downloading videos because it is configured to call <code>youtube-dl</code> with the correct command-line flags for the project.</p>
<h3 id="2-clean-videos">2. Clean videos</h3>
<p><code>./run.sh clean</code> removes videos from <code>data/input</code> that are the wrong size. This should be run after downloading videos.</p>
<h3 id="3-transcribe-source-videos">3. Transcribe source videos</h3>
<p><code>./run.sh transcribe</code> uses CMU Sphinx to create transcription files for all <code>mp4</code> files in <code>data/input</code> that do not already have them. Transcription files are saved next to the video files with an identical name plus <code>.transcription.txt</code>. E.g. <code>data/input/my_video.mp4.transcription.txt</code>. This process takes a very long time and it is recommended that you transcribe all videos in the background so that they can be processesed in parallel:</p>
<pre><code class="lang-bash">TRANSCRIBE_IN_BACKGROUND=1 ./run.sh transcribe
</code></pre>
<h3 id="4-cut-source-videos-into-word-clips">4. Cut source videos into word clips</h3>
<p><code>./run.sh cut</code> uses <code>*.transcription.txt</code> files to cut short word clips searching for words from both <code>data/lyrics/uncommon_words.txt</code> and <code>data/lyrics/common_words.txt</code> and save them to <code>data/clips/:word</code> (<strong>note</strong>: <code>:word</code> indicates a variable word). Clip filenames store information about the clip:</p>
<p><code>:cmu-sphinx-confidence_:duration_:in-point_:out-point_:source-video.mp4</code>. </p>
<p>E.g:</p>
<p><code>0.21_0.37_2.2e+02_2.2e+02_Bill Gates On Clean Energy, Donald Trump, And Stocks (Full Interview) _ Squawk Box _ CNBC-S5WJ11difCY.mp4</code></p>
<p>Any filenames in <code>data/input/cutignore.txt</code> will be skipped. Once MP4 files have been cut they will be added to this file to prevent re-cutting the same footage.</p>
<h3 id="5-cut-silence-clips">5. Cut silence clips</h3>
<p><code>./run.sh cut-silence</code> loads clips from <code>data/input_silence</code> and cuts them into 10 second clips saved to <code>data/words/SILENCE</code>. These clips are used in the <code>silence</code> task to generate a &quot;background&quot; silence cut.</p>
<h3 id="6-create-a-silence-supercut-to-use-as-background-">6. Create a silence supercut to use as &quot;background&quot;</h3>
<p><code>./run.sh silence</code> reads from clips in <code>data/clips/SILENCE</code> and creates a video that combines a subset of these clips using beat timings from <code>data/beats/kick-snare.csv</code>. The output file is saved to <code>data/output/silence.mp4</code> by default. Both of these configurations can be changed like so:</p>
<pre><code class="lang-bash">BEATS_FILE=data/beats/kick-only.csv SILENCE_OUTPUT=data/output/my_silence_video.mp4 ./run.sh silence
</code></pre>
<p>An ordered list of clips used to generate the silence output is saved next to the output file as &quot;:SILENCE_OUTPUT.logfile.txt&quot;, e.g. <code>data/output/silence.mp4.logfile.txt</code>.</p>
<h3 id="7-create-the-music-video">7. Create the music video</h3>
<p>Once all of the above tasks have been completed <code>./run.sh supercut</code> will create the final video, saving it to <code>data/output/output.mp4</code>. The output filename can be changed with:</p>
<pre><code class="lang-bash">OUTPUT=data/output/my_music_video.mp4 ./run.sh supercut
</code></pre>
<p>An ordered list of clips used to generate the output is saved next to the output file as &quot;:OUTPUT.logfile.txt&quot;, e.g. <code>data/output/output.mp4.logfile.txt</code>. </p>
<p>A list of file basenames from clips used to generate the output will also be written to <code>data/clips/output.mp4.clipignore.txt</code> where <code>output.mp4</code> is the name of the output file. Any clips in <code>data/clips/*.clipignore.txt</code> will be ignored when <code>./run.sh supercut</code> is run. This is to prevent consecutive supercuts from using the same word clips. It is the also a convention to add poor quality clips to <code>data/clips/global.clipignore.txt</code> to prevent them from being used in future videos.</p>
<h3 id="8-add-subtitles-with-ffmpeg-">8. Add subtitles with <code>ffmpeg</code></h3>
<p>An optional last step is to create a video that overlays the subtitles from <code>data/lyrics/dig-down-captions.srt</code> to the output of <code>./run.sh supercut</code>. The video file to be processed can be specified using <code>SUBS_INPUT</code>:</p>
<pre><code class="lang-bash">SUBS_INPUT=data/output/output.mp4 ./run.sh subs
</code></pre>
<p>Once complete, <code>data/output/output.mp4</code> will now have the subtitles &quot;baked&quot; into the video.</p>
<h2 id="other-tools">Other Tools</h2>
<p>A few helper tools have been added to the repo to add with miscellaneous tasks:</p>
<ol>
<li><code>video_duration.py</code></li>
<li><code>youtube_cc_search.py</code></li>
<li><code>plot_word_freq.py</code></li>
</ol>
<h3 id="-video_duration-py-"><code>video_duration.py</code></h3>
<p>Use this CLI to calculate the total duration of all video files in a directory.</p>
<pre><code class="lang-bash">python video_duration.py --input_dir data/input
# e.g. 157 videos, 72.2059838889 hours
</code></pre>
<h3 id="-youtube_cc_search-py-"><code>youtube_cc_search.py</code></h3>
<p>This tool was created to allow the download and full-text search of WebVTT subtitles from youtube via keyword search. The goal was to be able to know the transcript of videos before they were downloaded, so that rare words (e.g. &quot;clown&quot;) could be found quickly without having to download and transcribe entire videos that did not contain the target rare word.</p>
<p>There are two ways that the tool can be used: 1) download <code>.vtt</code> subtitles from youtube using keyword search (keyword hear refering to keywords in the video title or description, not searching for a target word) and 2) the full-text search downloaded <code>.vtt</code> files for the presence of a target rare word.</p>
<h4 id="1-download-vtt-files">1. Download <code>.vtt</code> files</h4>
<pre><code>python youtube_cc_search.py --download &quot;cbs news&quot;
</code></pre><p>This downloads <code>.vtt</code> subtitles for videos that match the &quot;cbs news&quot; keyword search using the YouTube Data API. <code>.vtt</code> files are saved to the <code>data/subtitle_search/</code> in a folder named <code>cbs news</code>. <code>.vtt</code> files are named using the YouTube video id of the video they caption as well as the language id (e.g. <code>kZUrOOHFUBQ.en.vtt</code>).</p>
<h4 id="2-search-downloaded-vtt-files">2. Search downloaded <code>.vtt</code> files</h4>
<pre><code>python youtube_cc_search.py --search &quot;clown&quot;
</code></pre><p>This usage uses full-text search to find the <code>.vtt</code> files in <code>data/subtitle_search</code> that contain the word &quot;clown&quot;. It prints a list of YouTube URLs of videos that can be expected to have at least one occurance of the search term.</p>
<p>Once searched, ids that contain results are added to <code>data/subtitle_search/idignore.txt</code> to prevent them from being searched again. On each new search, results that contain ids in the <code>idignore.txt</code> are filtered and removed before displaying URLs to the user. If you would like to search all <code>.vtt</code> files, simply delete or rename the <code>idignore.txt</code> file.</p>
<h3 id="-plot_word_freq-py-"><code>plot_word_freq.py</code></h3>
<p>This tool uses matplotlib to create a histogram that shows the number of word clips in each folder in <code>data/clips</code>.</p>
<pre><code>python plot_word_freq.py
</code></pre></body>
</html>
